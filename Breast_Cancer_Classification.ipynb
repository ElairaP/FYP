{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "#import sklearn\n",
    "#print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean Radius</th>\n",
       "      <th>Mean Texture</th>\n",
       "      <th>Mean Perimeter</th>\n",
       "      <th>Mean Area</th>\n",
       "      <th>Mean Smoothness</th>\n",
       "      <th>Mean Compactness</th>\n",
       "      <th>Mean Concavity</th>\n",
       "      <th>Mean Concave Points</th>\n",
       "      <th>Mean Symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst Radius</th>\n",
       "      <th>Worst Texture</th>\n",
       "      <th>Worst Perimeter</th>\n",
       "      <th>Worst Area</th>\n",
       "      <th>Worst Smoothness</th>\n",
       "      <th>Worst Compactness</th>\n",
       "      <th>Worst Concavity</th>\n",
       "      <th>Worst Concave Points</th>\n",
       "      <th>Worst Symmetry</th>\n",
       "      <th>Worst Fractal Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   Mean Symmetry  ...  Worst Radius  Worst Texture  Worst Perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   Worst Area  Worst Smoothness  Worst Compactness  Worst Concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   Worst Concave Points  Worst Symmetry  Worst Fractal Dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Breast-Cancer-Data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Breast_Cancer_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean Radius</th>\n",
       "      <th>Mean Texture</th>\n",
       "      <th>Mean Perimeter</th>\n",
       "      <th>Mean Area</th>\n",
       "      <th>Mean Smoothness</th>\n",
       "      <th>Mean Compactness</th>\n",
       "      <th>Mean Concavity</th>\n",
       "      <th>Mean Concave Points</th>\n",
       "      <th>Mean Symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst Radius</th>\n",
       "      <th>Worst Texture</th>\n",
       "      <th>Worst Perimeter</th>\n",
       "      <th>Worst Area</th>\n",
       "      <th>Worst Smoothness</th>\n",
       "      <th>Worst Compactness</th>\n",
       "      <th>Worst Concavity</th>\n",
       "      <th>Worst Concave Points</th>\n",
       "      <th>Worst Symmetry</th>\n",
       "      <th>Worst Fractal Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   Mean Symmetry  ...  Worst Radius  Worst Texture  Worst Perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   Worst Area  Worst Smoothness  Worst Compactness  Worst Concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   Worst Concave Points  Worst Symmetry  Worst Fractal Dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Breast_Cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Breast_Cancer_df[\"Diagnosis\"] = Breast_Cancer_df[\"Diagnosis\"].map({'B':0, 'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean Radius</th>\n",
       "      <th>Mean Texture</th>\n",
       "      <th>Mean Perimeter</th>\n",
       "      <th>Mean Area</th>\n",
       "      <th>Mean Smoothness</th>\n",
       "      <th>Mean Compactness</th>\n",
       "      <th>Mean Concavity</th>\n",
       "      <th>Mean Concave Points</th>\n",
       "      <th>Mean Symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst Radius</th>\n",
       "      <th>Worst Texture</th>\n",
       "      <th>Worst Perimeter</th>\n",
       "      <th>Worst Area</th>\n",
       "      <th>Worst Smoothness</th>\n",
       "      <th>Worst Compactness</th>\n",
       "      <th>Worst Concavity</th>\n",
       "      <th>Worst Concave Points</th>\n",
       "      <th>Worst Symmetry</th>\n",
       "      <th>Worst Fractal Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   Mean Symmetry  ...  Worst Radius  Worst Texture  Worst Perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   Worst Area  Worst Smoothness  Worst Compactness  Worst Concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   Worst Concave Points  Worst Symmetry  Worst Fractal Dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Breast_Cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Breast_Cancer_df['Diagnosis'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = Breast_Cancer_df.drop('Diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_points, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mean Radius  Mean Texture  Mean Perimeter  Mean Area  Mean Smoothness  \\\n",
      "512        13.40         20.52           88.64      556.7          0.11060   \n",
      "457        13.21         25.25           84.10      537.9          0.08791   \n",
      "439        14.02         15.66           89.59      606.5          0.07966   \n",
      "298        14.26         18.17           91.22      633.1          0.06576   \n",
      "37         13.03         18.42           82.61      523.8          0.08983   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "213        17.42         25.56          114.50      948.0          0.10060   \n",
      "519        12.75         16.70           82.51      493.8          0.11250   \n",
      "432        20.18         19.54          133.80     1250.0          0.11330   \n",
      "516        18.31         20.58          120.80     1052.0          0.10680   \n",
      "500        15.04         16.74           98.73      689.4          0.09883   \n",
      "\n",
      "     Mean Compactness  Mean Concavity  Mean Concave Points  Mean Symmetry  \\\n",
      "512           0.14690         0.14450              0.08172         0.2116   \n",
      "457           0.05205         0.02772              0.02068         0.1619   \n",
      "439           0.05581         0.02087              0.02652         0.1589   \n",
      "298           0.05220         0.02475              0.01374         0.1635   \n",
      "37            0.03766         0.02562              0.02923         0.1467   \n",
      "..                ...             ...                  ...            ...   \n",
      "213           0.11460         0.16820              0.06597         0.1308   \n",
      "519           0.11170         0.03880              0.02995         0.2120   \n",
      "432           0.14890         0.21330              0.12590         0.1724   \n",
      "516           0.12480         0.15690              0.09451         0.1860   \n",
      "500           0.13640         0.07721              0.06142         0.1668   \n",
      "\n",
      "     Mean Fractal Dimension  ...  Worst Radius  Worst Texture  \\\n",
      "512                 0.07325  ...         16.41          29.66   \n",
      "457                 0.05584  ...         14.35          34.23   \n",
      "439                 0.05586  ...         14.91          19.31   \n",
      "298                 0.05586  ...         16.22          25.26   \n",
      "37                  0.05863  ...         13.30          22.81   \n",
      "..                      ...  ...           ...            ...   \n",
      "213                 0.05866  ...         18.07          28.07   \n",
      "519                 0.06623  ...         14.45          21.74   \n",
      "432                 0.06053  ...         22.03          25.07   \n",
      "516                 0.05941  ...         21.86          26.20   \n",
      "500                 0.06869  ...         16.76          20.43   \n",
      "\n",
      "     Worst Perimeter  Worst Area  Worst Smoothness  Worst Compactness  \\\n",
      "512           113.30       844.4           0.15740            0.38560   \n",
      "457            91.29       632.9           0.12890            0.10630   \n",
      "439            96.53       688.9           0.10340            0.10170   \n",
      "298           105.80       819.7           0.09445            0.21670   \n",
      "37             84.46       545.9           0.09701            0.04619   \n",
      "..               ...         ...               ...                ...   \n",
      "213           120.40      1021.0           0.12430            0.17930   \n",
      "519            93.63       624.1           0.14750            0.19790   \n",
      "432           146.00      1479.0           0.16650            0.29420   \n",
      "516           142.20      1493.0           0.14920            0.25360   \n",
      "500           109.70       856.9           0.11350            0.21760   \n",
      "\n",
      "     Worst Concavity  Worst Concave Points  Worst Symmetry  \\\n",
      "512          0.51060               0.20510          0.3585   \n",
      "457          0.13900               0.06005          0.2444   \n",
      "439          0.06260               0.08216          0.2136   \n",
      "298          0.15650               0.07530          0.2636   \n",
      "37           0.04833               0.05013          0.1987   \n",
      "..               ...                   ...             ...   \n",
      "213          0.28030               0.10990          0.1603   \n",
      "519          0.14230               0.08045          0.3071   \n",
      "432          0.53080               0.21730          0.3032   \n",
      "516          0.37590               0.15100          0.3074   \n",
      "500          0.18560               0.10180          0.2177   \n",
      "\n",
      "     Worst Fractal Dimension  \n",
      "512                  0.11090  \n",
      "457                  0.06788  \n",
      "439                  0.06710  \n",
      "298                  0.07676  \n",
      "37                   0.06169  \n",
      "..                       ...  \n",
      "213                  0.06818  \n",
      "519                  0.08557  \n",
      "432                  0.08075  \n",
      "516                  0.07863  \n",
      "500                  0.08549  \n",
      "\n",
      "[114 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_val = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_default_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks using Adam optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\airap\\.conda\\envs\\fyp\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlp__activation': 'relu', 'mlp__alpha': 0.0001, 'mlp__batch_size': 32, 'mlp__hidden_layer_sizes': (30, 20), 'mlp__learning_rate_init': 0.013881386765077483, 'mlp__max_iter': 100, 'mlp__solver': 'adam'}\n",
      "0.9759420289855072\n"
     ]
    }
   ],
   "source": [
    "mlp_adam_search_space = {'mlp__hidden_layer_sizes':[(30,20)],'mlp__activation': ['relu'], 'mlp__solver': ['adam'], 'mlp__batch_size': [32],\n",
    "                        'mlp__alpha': [1e-4],\n",
    "                        'mlp__learning_rate_init': loguniform(1e-2, 0.5),\n",
    "                        'mlp__max_iter': [100]}\n",
    "\n",
    "mlp_adam_rs_search = RandomizedSearchCV(mlp_default_pipe, mlp_adam_search_space, n_iter=50, scoring='accuracy', cv = skf_val)\n",
    "mlp_adam_search_result = mlp_adam_rs_search.fit(X_train, y_train)\n",
    "print(mlp_adam_search_result.best_params_)\n",
    "print(mlp_adam_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9669565217391305\n"
     ]
    }
   ],
   "source": [
    "mlp_adam_tuned = MLPClassifier(hidden_layer_sizes=(30, 20), activation='relu', solver='adam',batch_size=32 ,alpha= 0.0001, learning_rate_init=0.0650, max_iter=80)\n",
    "\n",
    "mlp_adam_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', mlp_adam_tuned)])\n",
    "\n",
    "mlp_adam_score = cross_val_score(mlp_adam_pipe, X_train, y_train, scoring='accuracy', cv=skf_val)\n",
    "print(mlp_adam_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks using lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlp__solver': 'lbfgs', 'mlp__max_iter': 50, 'mlp__hidden_layer_sizes': (30, 20), 'mlp__alpha': 0.0001, 'mlp__activation': 'relu'}\n",
      "0.9694202898550724\n"
     ]
    }
   ],
   "source": [
    "mlp_lbfgs_search_space = {'mlp__hidden_layer_sizes':[(30,20)],'mlp__activation': ['relu'], 'mlp__solver': ['lbfgs'], \n",
    "                        'mlp__alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "                        'mlp__max_iter': [50]}\n",
    "\n",
    "mlp_lbfgs_rs_search = RandomizedSearchCV(mlp_default_pipe, mlp_lbfgs_search_space, n_iter=4, scoring='accuracy', cv = skf_val)\n",
    "mlp_lbfgs_search_result = mlp_lbfgs_rs_search.fit(X_train, y_train)\n",
    "print(mlp_lbfgs_search_result.best_params_)\n",
    "print(mlp_lbfgs_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9648792270531402\n"
     ]
    }
   ],
   "source": [
    "mlp_lbfgs_tuned = MLPClassifier(hidden_layer_sizes=(30, 20), activation='relu', solver='lbfgs', alpha= 0.001, max_iter=50)\n",
    "\n",
    "mlp_lbfgs_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', mlp_lbfgs_tuned)])\n",
    "\n",
    "mlp_lbfgs_score = cross_val_score(mlp_lbfgs_pipe, X_train, y_train, scoring='accuracy', cv=skf_val)\n",
    "print(mlp_lbfgs_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks using sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlp__activation': 'relu', 'mlp__alpha': 0.0001, 'mlp__batch_size': 32, 'mlp__hidden_layer_sizes': (30, 20), 'mlp__learning_rate': 'constant', 'mlp__learning_rate_init': 0.020850669248599966, 'mlp__max_iter': 100, 'mlp__momentum': 0.95, 'mlp__solver': 'sgd'}\n",
      "0.9759420289855072\n"
     ]
    }
   ],
   "source": [
    "mlp_sgd_search_space = {'mlp__hidden_layer_sizes':[(30,20)],'mlp__activation': ['relu'], 'mlp__solver': ['sgd'], \n",
    "                        'mlp__alpha': [1e-4], 'mlp__batch_size': [32],\n",
    "                        'mlp__learning_rate': ['constant'], 'mlp__learning_rate_init': loguniform(1e-2, 0.9),\n",
    "                        'mlp__momentum': [0.95, 0.99], 'mlp__max_iter': [100]}\n",
    "\n",
    "mlp_sgd_rs_search = RandomizedSearchCV(mlp_default_pipe, mlp_sgd_search_space, n_iter=50, scoring='accuracy', cv = skf_val)\n",
    "mlp_sgd_search_result = mlp_sgd_rs_search.fit(X_train, y_train)\n",
    "print(mlp_sgd_search_result.best_params_)\n",
    "print(mlp_sgd_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758937198067633\n"
     ]
    }
   ],
   "source": [
    "mlp_sgd_tuned = MLPClassifier(hidden_layer_sizes=(30, 20), activation='relu', solver='sgd',batch_size=32, alpha= 0.0001, learning_rate='constant', learning_rate_init=0.0550, \n",
    "                                 max_iter=70, momentum=0.95)\n",
    "\n",
    "mlp_sgd_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', mlp_sgd_tuned)])\n",
    "\n",
    "mlp_sgd_score = cross_val_score(mlp_sgd_pipe, X_train, y_train, scoring='accuracy', cv=skf_val)\n",
    "print(mlp_sgd_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', mlp_sgd_tuned)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision:  0.9655766253869971\n",
      "test recall:  0.9643382352941176\n",
      "test f1:  0.9639408793820557\n",
      "test accuracy:  0.973719806763285\n",
      "train f1:  1.0\n",
      "train accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "mlp_scores = cross_validate(mlp_pipe, X_train, y_train, scoring=('precision', 'recall', 'f1', 'accuracy'), cv=skf_val, return_train_score=True)\n",
    "print(\"test precision: \", mlp_scores['test_precision'].mean())\n",
    "print(\"test recall: \", mlp_scores['test_recall'].mean())\n",
    "print(\"test f1: \", mlp_scores['test_f1'].mean())\n",
    "print(\"test accuracy: \", mlp_scores['test_accuracy'].mean())\n",
    "\n",
    "print(\"train f1: \", mlp_scores['train_f1'].mean())\n",
    "print(\"train accuracy: \", mlp_scores['train_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('mlp',\n",
       "                 MLPClassifier(batch_size=32, hidden_layer_sizes=(30, 20),\n",
       "                               learning_rate_init=0.055, max_iter=70,\n",
       "                               momentum=0.95, solver='sgd'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "mlp_pipe_predictions = mlp_pipe.predict(X_test)\n",
    "print(mlp_pipe_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9583333333333334\n",
      "Recall:  0.9787234042553191\n",
      "f1:  0.968421052631579\n",
      "accuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "mlp_pipe_precision = precision_score(y_test, mlp_pipe_predictions)\n",
    "mlp_pipe_recall = recall_score(y_test, mlp_pipe_predictions)\n",
    "mlp_pipe_f1 = f1_score(y_test, mlp_pipe_predictions)\n",
    "mlp_pipe_accuracy = mlp_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Precision: \", mlp_pipe_precision)\n",
    "print(\"Recall: \", mlp_pipe_recall)\n",
    "print(\"f1: \", mlp_pipe_f1)\n",
    "print(\"accuracy: \", mlp_pipe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_default_pipe = Pipeline([('scaler', StandardScaler()), ('svm', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 99.70176829743455, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "0.9802898550724638\n"
     ]
    }
   ],
   "source": [
    "svm_search_space = [{'svm__kernel': ['rbf'], 'svm__C': loguniform(1e-2, 100), 'svm__gamma': [0.1,0.01,0.001,0.0001]},\n",
    "                    {'svm__kernel': ['linear'], 'svm__C': loguniform(1e-2, 100)}]\n",
    "\n",
    "# {'svm__kernel': ['poly'], 'svm__C': loguniform(1e-3, 1e2), 'svm__degree': [2, 3, 4], 'svm__gamma': [0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "svm_rs_search = RandomizedSearchCV(svm_default_pipe, svm_search_space, n_iter=100, scoring='accuracy', cv = skf_val)\n",
    "svm_search_result = svm_rs_search.fit(X_train, y_train)\n",
    "print(svm_search_result.best_params_)\n",
    "print(svm_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.99375\n",
      "Recall:  0.9580882352941176\n",
      "test f1:  0.975183284457478\n",
      "test accuracy:  0.9824637681159419\n",
      "train f1:  0.9798515701748475\n",
      "train accuracy:  0.985592462281591\n"
     ]
    }
   ],
   "source": [
    "svm_tuned = SVC(C= 6.0, kernel = 'rbf', gamma=0.01)\n",
    "# 2.77, rbf, gamma= 0.0140\n",
    "svm_pipe = Pipeline([('scaler', StandardScaler()), ('svm', svm_tuned)])\n",
    "\n",
    "svm_tuned_scores = cross_validate(svm_pipe, X_train, y_train, scoring=('precision', 'recall', 'f1', 'accuracy') ,cv=skf_val, return_train_score=True)\n",
    "print(\"Precision: \", svm_tuned_scores['test_precision'].mean())\n",
    "print(\"Recall: \", svm_tuned_scores['test_recall'].mean())\n",
    "print(\"test f1: \", svm_tuned_scores['test_f1'].mean())\n",
    "print(\"test accuracy: \", svm_tuned_scores['test_accuracy'].mean())\n",
    "\n",
    "print(\"train f1: \", svm_tuned_scores['train_f1'].mean())\n",
    "print(\"train accuracy: \", svm_tuned_scores['train_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('svm', SVC(C=6.0, gamma=0.01))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "svm_pipe_predictions = svm_pipe.predict(X_test)\n",
    "print(svm_pipe_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9787234042553191\n",
      "Recall:  0.9787234042553191\n",
      "f1:  0.9787234042553191\n",
      "Accuracy:  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "svm_pipe_precision = precision_score(y_test, svm_pipe_predictions)\n",
    "svm_pipe_recall = recall_score(y_test, svm_pipe_predictions)\n",
    "svm_pipe_f1 = f1_score(y_test, svm_pipe_predictions)\n",
    "svm_pipe_accuracy = svm_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Precision: \", svm_pipe_precision)\n",
    "print(\"Recall: \", svm_pipe_recall)\n",
    "print(\"f1: \", svm_pipe_f1)\n",
    "print(\"Accuracy: \", svm_pipe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_default_pipe = Pipeline([('scaler', StandardScaler()), ('forest', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forest__n_estimators': 100, 'forest__min_samples_split': 4, 'forest__min_samples_leaf': 1, 'forest__max_features': 'log2'}\n",
      "0.9648792270531402\n"
     ]
    }
   ],
   "source": [
    "forest_search_space = {'forest__min_samples_split': [2,3,4,5,6,7,8], 'forest__min_samples_leaf': [1,2,3,4,5,6,7], 'forest__max_features': ['sqrt', 'log2'], 'forest__n_estimators': [75, 100, 125, 150]}\n",
    "\n",
    "forest_rs_search = RandomizedSearchCV(forest_default_pipe, forest_search_space, n_iter=120, scoring='accuracy', cv=skf_val)\n",
    "forest_search_result = forest_rs_search.fit(X_train, y_train)\n",
    "print(forest_search_result.best_params_)\n",
    "print(forest_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision:  0.9566970121381886\n",
      "test recall:  0.9334558823529411\n",
      "test f1:  0.9441825821237586\n",
      "test accuracy:  0.9604830917874396\n",
      "train f1:  1.0\n",
      "train accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "forest_tuned = RandomForestClassifier(n_estimators=125, min_samples_split=3, min_samples_leaf=1, max_features='log2')\n",
    "\n",
    "forest_pipe = Pipeline([('scaler', StandardScaler()), ('forest', forest_tuned)])\n",
    "\n",
    "forest_tuned_scores = cross_validate(forest_pipe, X_train, y_train, scoring=('precision', 'recall', 'f1', 'accuracy'), cv=skf_val, return_train_score=True)\n",
    "print(\"test precision: \", forest_tuned_scores['test_precision'].mean())\n",
    "print(\"test recall: \", forest_tuned_scores['test_recall'].mean())\n",
    "print(\"test f1: \", forest_tuned_scores['test_f1'].mean())\n",
    "print(\"test accuracy: \", forest_tuned_scores['test_accuracy'].mean())\n",
    "\n",
    "print(\"train f1: \", forest_tuned_scores['train_f1'].mean())\n",
    "print(\"train accuracy: \", forest_tuned_scores['train_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('forest',\n",
       "                 RandomForestClassifier(max_features='log2',\n",
       "                                        min_samples_split=3,\n",
       "                                        n_estimators=125))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "forest_pipe_predictions = forest_pipe.predict(X_test)\n",
    "print(forest_pipe_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9387755102040817\n",
      "Recall:  0.9787234042553191\n",
      "f1:  0.9583333333333333\n",
      "Accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "forest_pipe_precision = precision_score(y_test, forest_pipe_predictions)\n",
    "forest_pipe_recall = recall_score(y_test, forest_pipe_predictions)\n",
    "forest_pipe_f1 = f1_score(y_test, forest_pipe_predictions)\n",
    "forest_pipe_accuracy = forest_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Precision: \", forest_pipe_precision)\n",
    "print(\"Recall: \", forest_pipe_recall)\n",
    "print(\"f1: \", forest_pipe_f1)\n",
    "print(\"Accuracy: \", forest_pipe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_default_pipe = Pipeline([('scaler', StandardScaler()), ('dt', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__min_samples_split': 4, 'dt__min_samples_leaf': 2, 'dt__max_features': 26, 'dt__max_depth': 7}\n",
      "0.9516908212560387\n"
     ]
    }
   ],
   "source": [
    "dt_search_space = [{'dt__max_depth': [5,6,7,8], 'dt__min_samples_split': [2,3,4,5,6,7,8], 'dt__min_samples_leaf': [1,2,3,4,5], 'dt__max_features': [30, 29, 28, 27, 26, 25, 24]},\n",
    "                      {'dt__max_depth': [5,6,7,8], 'dt__min_samples_split': [2,3,4,5,6,7,8], 'dt__min_samples_leaf': [1,2,3,3,4,5], 'dt__max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "dt_rs_search = RandomizedSearchCV(dt_default_pipe, dt_search_space, n_iter=100, scoring='accuracy', cv = skf_val)\n",
    "dt_search_result = dt_rs_search.fit(X_train, y_train)\n",
    "print(dt_search_result.best_params_)\n",
    "print(dt_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision:  0.9062816354612021\n",
      "test recall:  0.8977941176470587\n",
      "test f1:  0.9009723728200958\n",
      "test accuracy:  0.9277777777777778\n",
      "train f1:  0.989769975798505\n",
      "train accuracy:  0.9926715963981156\n"
     ]
    }
   ],
   "source": [
    "dt_tuned = DecisionTreeClassifier(max_depth=7, min_samples_split=3, min_samples_leaf=1, max_features='log2')\n",
    "\n",
    "dt_pipe = Pipeline([('scaler', StandardScaler()), ('dt', dt_tuned)])\n",
    "\n",
    "\n",
    "dt_tuned_scores = cross_validate(dt_pipe, X_train, y_train, scoring=('precision', 'recall', 'f1', 'accuracy'), cv=skf_val, return_train_score=True)\n",
    "print(\"test precision: \", dt_tuned_scores['test_precision'].mean())\n",
    "print(\"test recall: \", dt_tuned_scores['test_recall'].mean())\n",
    "print(\"test f1: \", dt_tuned_scores['test_f1'].mean())\n",
    "print(\"test accuracy: \", dt_tuned_scores['test_accuracy'].mean())\n",
    "\n",
    "print(\"train f1: \", dt_tuned_scores['train_f1'].mean())\n",
    "print(\"train accuracy: \", dt_tuned_scores['train_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('dt',\n",
       "                 DecisionTreeClassifier(max_depth=7, max_features='log2',\n",
       "                                        min_samples_split=3))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "dt_pipe_predictions = dt_pipe.predict(X_test)\n",
    "print(dt_pipe_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9347826086956522\n",
      "Recall:  0.9148936170212766\n",
      "f1:  0.924731182795699\n",
      "Accuracy:  0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "dt_pipe_precision = precision_score(y_test, dt_pipe_predictions)\n",
    "dt_pipe_recall = recall_score(y_test, dt_pipe_predictions)\n",
    "dt_pipe_f1 = f1_score(y_test, dt_pipe_predictions)\n",
    "dt_pipe_accuracy = dt_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Precision: \", dt_pipe_precision)\n",
    "print(\"Recall: \", dt_pipe_recall)\n",
    "print(\"f1: \", dt_pipe_f1)\n",
    "print(\"Accuracy: \", dt_pipe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_default_pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.37875565550179374}\n",
      "0.9824154589371981\n"
     ]
    }
   ],
   "source": [
    "lr_search_space = {'lr__C': loguniform(1e-2, 10)}\n",
    "\n",
    "lr_rs_search = RandomizedSearchCV(lr_default_pipe, lr_search_space, n_iter=50, scoring='accuracy', cv=skf_val)\n",
    "lr_search_result = lr_rs_search.fit(X_train, y_train)\n",
    "print(lr_search_result.best_params_)\n",
    "print(lr_search_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision:  0.9877777777777779\n",
      "test recall:  0.9636029411764706\n",
      "test f1:  0.9749593283061024\n",
      "test accuracy:  0.9824154589371981\n",
      "train f1:  0.9833274109088304\n",
      "train accuracy:  0.9880344683642435\n"
     ]
    }
   ],
   "source": [
    "lr_tuned = LogisticRegression(C=0.45)\n",
    "\n",
    "lr_pipe = Pipeline([('scaler', StandardScaler()), ('lr', lr_tuned)])\n",
    "\n",
    "lr_tuned_scores = cross_validate(lr_pipe, X_train, y_train, scoring=('precision', 'recall', 'f1', 'accuracy'), cv=skf_val, return_train_score=True)\n",
    "print(\"test precision: \", lr_tuned_scores['test_precision'].mean())\n",
    "print(\"test recall: \", lr_tuned_scores['test_recall'].mean())\n",
    "print(\"test f1: \", lr_tuned_scores['test_f1'].mean())\n",
    "print(\"test accuracy: \", lr_tuned_scores['test_accuracy'].mean())\n",
    "\n",
    "print(\"train f1: \", lr_tuned_scores['train_f1'].mean())\n",
    "print(\"train accuracy: \", lr_tuned_scores['train_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lr', LogisticRegression(C=0.45))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_predictions = lr_pipe.predict(X_test)\n",
    "print(lr_pipe_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9565217391304348\n",
      "Recall:  0.9361702127659575\n",
      "f1:  0.9462365591397849\n",
      "Accuracy:  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_precision = precision_score(y_test, lr_pipe_predictions)\n",
    "lr_pipe_recall = recall_score(y_test, lr_pipe_predictions)\n",
    "lr_pipe_f1 = f1_score(y_test, lr_pipe_predictions)\n",
    "lr_pipe_accuracy = lr_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Precision: \", lr_pipe_precision)\n",
    "print(\"Recall: \", lr_pipe_recall)\n",
    "print(\"f1: \", lr_pipe_f1)\n",
    "print(\"Accuracy: \", lr_pipe_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
